{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcd1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda5ff2",
   "metadata": {},
   "source": [
    "*Loading data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f823391",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa = pd.read_json('D:\\\\Downloads\\\\TechQA\\\\TechQA\\\\training_and_dev\\\\training_Q_A.json')\n",
    "dev_qa = pd.read_json('D:\\\\Downloads\\\\TechQA\\\\TechQA\\\\training_and_dev\\\\dev_Q_A.json')\n",
    "train_corpus = pd.read_json('D:\\\\Downloads\\\\TechQA\\\\TechQA\\\\training_and_dev\\\\training_dev_technotes.json', orient='index')\n",
    "train_sections = pd.read_json('D:\\\\Downloads\\\\TechQA\\\\TechQA\\\\training_and_dev\\\\training_dev_technotes.sections.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a27eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_qa.query('`ANSWERABLE` == \"Y\" and `ANSWER` != \"\"').merge(train_corpus, how='left', left_on='DOCUMENT', right_on='id')[['QUESTION_TITLE', \n",
    "                                                                                                                  'QUESTION_TEXT',\n",
    "                                                                                                                  'DOCUMENT',\n",
    "                                                                                                                  'ANSWER',\n",
    "                                                                                                                  'START_OFFSET',\n",
    "                                                                                                                  'END_OFFSET', \n",
    "                                                                                                                  'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eded4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev_qa.query('`ANSWERABLE` == \"Y\" and `ANSWER` != \"\"').merge(train_corpus, how='left', left_on='DOCUMENT', right_on='id')[['QUESTION_TITLE', \n",
    "                                                                                                                  'QUESTION_TEXT',\n",
    "                                                                                                                  'DOCUMENT',\n",
    "                                                                                                                  'ANSWER',\n",
    "                                                                                                                  'START_OFFSET',\n",
    "                                                                                                                  'END_OFFSET', \n",
    "                                                                                                                  'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03d80a",
   "metadata": {},
   "source": [
    "*Merging train and dev sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891a5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['split'] = \"train\"\n",
    "dev['split'] = \"dev\"\n",
    "\n",
    "techqa = pd.concat([train, dev]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03ee1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "techqa = techqa.drop_duplicates(subset=['ANSWER', \"title\", \"QUESTION_TEXT\"]).drop_duplicates(subset=['QUESTION_TEXT', 'QUESTION_TITLE'])\n",
    "techqa.START_OFFSET = techqa.START_OFFSET.apply(int)\n",
    "techqa.END_OFFSET = techqa.END_OFFSET.apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d21357",
   "metadata": {},
   "source": [
    "*Filtering duplicated titles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dcc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "techqa = techqa.query(\n",
    "    '~`title`.str.contains(\"IBM Action required for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0 for security vulnerabilities in Red Hat Linux\")')\n",
    "techqa = techqa.query(\n",
    "    '~`title`.str.contains(\"IBM Security Bulletin:  Multiple vulnerabilities in IBM Java Runtime affect API Connect - United States\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff7dd8",
   "metadata": {},
   "source": [
    "*Changing overlapping chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ccde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunk_overlaps(df: pd.DataFrame):\n",
    "    # documents with several queries\n",
    "    doc_idx = df.DOCUMENT.value_counts()[df.DOCUMENT.value_counts() != 1].index\n",
    "    id2change = {}\n",
    "    for didx in doc_idx:\n",
    "        # check if queries have different chunk as answer\n",
    "        if df.query('`DOCUMENT` == @didx').ANSWER.value_counts().shape[0] != 1:\n",
    "            # find start and end of chunks\n",
    "            intervals = list(set([tuple(el) for el in df.query('`DOCUMENT` == @didx')[['START_OFFSET', 'END_OFFSET']].values.tolist()]))\n",
    "            intervals = sorted(intervals, key=lambda x: x[0])\n",
    "            # check if 2 neighbor chunk overlap\n",
    "            for i in range(len(intervals) -1):\n",
    "                if pd.Interval(*intervals[i]).overlaps(pd.Interval(*intervals[i + 1])):\n",
    "                    start = min([intervals[i][0], intervals[i+1][0]])\n",
    "                    end = max([intervals[i][1], intervals[i+1][1]])\n",
    "                    id2change[didx] = []\n",
    "                    id2change[didx].append({intervals[i]: (start, end)})\n",
    "                    id2change[didx].append({intervals[i+1]: (start, end)})\n",
    "    return id2change\n",
    "\n",
    "\n",
    "def change_overlapping_chunks(df: pd.DataFrame, id2change: dict):\n",
    "    overlap_df = []\n",
    "    drop_mask = []\n",
    "    # iterate dict {didx: [(idx_start_old, idx_end_old): (idx_start_new, idx_end_new)]}\n",
    "    for didx, id_dicts in id2change.items():\n",
    "        for id_d in id_dicts:\n",
    "            start, end = [e for e in id_d.keys()][0]\n",
    "            new_start, new_end = [e for e in id_d.values()][0]\n",
    "            # find current query df id\n",
    "            i = df.query('`DOCUMENT` == @didx and `START_OFFSET` == @start and `END_OFFSET` == @end').index.values[0]\n",
    "            drop_mask.append(i)\n",
    "            # append current query info\n",
    "            i_dict = df.loc[i].to_dict()\n",
    "            i_dict['START_OFFSET'] = new_start\n",
    "            i_dict['END_OFFSET'] = new_end\n",
    "            overlap_df.append(i_dict)\n",
    "    overlap_df = pd.DataFrame(overlap_df)\n",
    "    return pd.concat([df.loc[[i for i in df.index if not i in drop_mask]], overlap_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c25360",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2change = find_chunk_overlaps(techqa)\n",
    "no_overlap_techqa = change_overlapping_chunks(techqa, idx2change)\n",
    "\n",
    "idx2change = find_chunk_overlaps(no_overlap_techqa)\n",
    "no_overlap_techqa = change_overlapping_chunks(no_overlap_techqa, idx2change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225cbfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_chunk_overlaps(no_overlap_techqa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88dfd5e",
   "metadata": {},
   "source": [
    "*Finding no-answer chunks from the same documents*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7990d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_no_answer_chunks(df: pd.DataFrame, technotes: pd.DataFrame):\n",
    "    doc_sections = []\n",
    "    for didx in df.DOCUMENT.unique():\n",
    "        intervals = list(set([tuple(el) for el in df.query('`DOCUMENT` == @didx')[['START_OFFSET', 'END_OFFSET']].values.tolist()]))\n",
    "        intervals = sorted(intervals, key=lambda x: x[0])\n",
    "        for sec in technotes.query('`id` == @didx').sections.values[0]:\n",
    "            if sec['end'] - sec['start'] > 100:\n",
    "                for inter in intervals:\n",
    "                    if pd.Interval(sec['start'], sec['end']).overlaps(pd.Interval(*inter)):\n",
    "                        break\n",
    "                else:\n",
    "                    if not sec['text'].lower().strip().startswith('question'):\n",
    "                        doc_sections.append({\n",
    "                            \"DOCUMENT\": didx,\n",
    "                            \"START_OFFSET\": sec['start'],\n",
    "                            \"END_OFFSET\": sec['end'],\n",
    "                            \"title\": df.query('`DOCUMENT` == @didx').title.values[0],\n",
    "                            \"ANSWER\": sec['text'],\n",
    "                            \"QUESTION_TITLE\": np.nan,\n",
    "                            \"QUESTION_TEXT\": np.nan,\n",
    "                            \"split\": 'no-answer'\n",
    "                        })\n",
    "    doc_sections = pd.DataFrame(doc_sections)\n",
    "    return pd.concat([df, doc_sections]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18be84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfilled_techqa = find_no_answer_chunks(no_overlap_techqa, train_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba8e92",
   "metadata": {},
   "source": [
    "*Formatting text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "327c8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfilled_techqa.ANSWER = fullfilled_techqa.ANSWER.apply(lambda x: x.strip().replace('\\n\\n', '\\n'))\n",
    "fullfilled_techqa.title = fullfilled_techqa.title.apply(lambda x: x.strip().replace('\\n\\n', '\\n'))\n",
    "\n",
    "queries = []\n",
    "for title, text in zip(fullfilled_techqa.QUESTION_TITLE, fullfilled_techqa.QUESTION_TEXT):\n",
    "    if isinstance(title, str) and isinstance(text, str):\n",
    "        queries.append(title.strip().replace('\\n\\n', '\\n') + '\\n' + text.strip().replace('\\n\\n', '\\n'))\n",
    "    else:\n",
    "        queries.append(title)\n",
    "fullfilled_techqa['query'] = queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e897313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((489,), (489,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullfilled_techqa.title.unique().shape, fullfilled_techqa.DOCUMENT.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfilled_techqa[['DOCUMENT', 'title', 'ANSWER', 'query']].rename(columns={\"DOCUMENT\": \"document_id\", \"ANSWER\": \"text\"}).to_csv('techqa.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval-research-mipt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
